import os
import json
import base64
from datetime import datetime
import feedparser
import google.generativeai as genai
from github import Github, GithubException
import streamlit as st

# Load environment variables (for local dev)
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

class GitHubStorage:
    def __init__(self, token, repo_name):
        self.github = Github(token)
        self.repo = self.github.get_repo(repo_name)

    def load_json(self, filename):
        """Load JSON file from GitHub repository."""
        try:
            content_file = self.repo.get_contents(filename)
            json_content = base64.b64decode(content_file.content).decode('utf-8')
            return json.loads(json_content)
        except GithubException as e:
            if e.status == 404:
                return None
            raise e
        except Exception as e:
            print(f"Error loading {filename}: {e}")
            return None

    def save_json(self, filename, content):
        """Save Python object as JSON file to GitHub repository."""
        try:
            json_content = json.dumps(content, indent=2, ensure_ascii=False)
            
            try:
                # Try to get existing file to update
                contents = self.repo.get_contents(filename)
                self.repo.update_file(
                    path=filename,
                    message=f"Update {filename}",
                    content=json_content,
                    sha=contents.sha
                )
            except GithubException as e:
                if e.status == 404:
                    # File doesn't exist, create it
                    self.repo.create_file(
                        path=filename,
                        message=f"Create {filename}",
                        content=json_content
                    )
                else:
                    raise e
            return True
        except Exception as e:
            print(f"Error saving {filename}: {e}")
            return False

def fetch_and_analyze(rss_feeds, api_key):
    """
    Fetch news from RSS feeds and analyze using Gemini.
    
    Args:
        rss_feeds (list): List of dicts with 'name' and 'url'.
        api_key (str): Google Gemini API Key.
        
    Returns:
        str: Markdown report generated by Gemini.
    """
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel('gemini-flash-latest') # Using verified working model

    all_news = []
    
    for feed in rss_feeds:
        try:
            parsed_feed = feedparser.parse(feed['url'])
            # Get top 10 entries to ensure enough content for 10+ headlines
            entries = parsed_feed.entries[:10]
            
            feed_news = []
            for entry in entries:
                title = entry.get('title', 'No Title')
                link = entry.get('link', '#')
                summary = entry.get('summary', entry.get('description', 'No summary'))
                # Clean summary tags if necessary, but Gemini handles it well
                feed_news.append(f"- Title: {title}\n  Link: {link}\n  Summary: {summary[:500]}...") # Truncate summary
            
            if feed_news:
                all_news.append(f"## Source: {feed['name']}\n" + "\n".join(feed_news))
        except Exception as e:
            print(f"Error fetching {feed['name']}: {e}")
            continue

    if not all_news:
        return "No news found."

    prompt = f"""
    You are an expert IT News Anchor. Analyze the following news items and create a comprehensive daily briefing.

    Requirements:
    1. **AR/XR SECTION FIRST**: Identify any news related to AR Glasses, XR Headsets, Smart Glasses, or Extended Reality (XR). Group them into a dedicated section at the very top.
    2. **General News**: Select at least 10 other distinct and important news items for the general briefing.
    3. **Deep Dive**: Provide an EXTENSIVE Deep Dive into the single most significant topic (can be from AR/XR or general).
    4. **Bilingual**: For EVERY section (AR/XR, Headlines, and Deep Dive), provide content in **English first**, followed immediately by the **Korean translation**.

    Input News:
    {chr(10).join(all_news)}
    
    Output Format (Markdown):
    ## üï∂Ô∏è AR/XR Glasses & Headsets (AR/XR Îâ¥Ïä§)
    (If no specific AR/XR news is found, summarize any wearable or display tech, or briefly mention "No significant AR/XR news today.")
    - **[English Headline]**
      [English Summary]
      *(kr) [Korean Headline] - [Korean Summary]*

    ## üöÄ Today's IT Briefing (Ïò§ÎäòÏùò IT Î∏åÎ¶¨Ìïë)
    
    - **1. [English Headline]**
      [English Summary]
      *(kr) [Korean Headline] - [Korean Summary]*
      
    - **2. [English Headline]**
      ...
    (Continue for at least 10 items)
    
    ### üîç Deep Dive (Ïã¨Ï∏µ Î∂ÑÏÑù: [Topic Name])
    **[English Analysis]**
    (Write a detailed, multi-paragraph analysis of the topic, explaining why it matters, technical details, and future implications.)
    
    **[Korean Translation]**
    (Translate the above analysis into Korean.)
    
    ### üè∑Ô∏è Hashtags
    #Tag1 #Tag2 #Tag3 ...
    """
    
    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"Error analyzing news: {e}"
